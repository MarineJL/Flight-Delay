{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "data = pd.read_csv(\"/Users/marinejacquemin/Desktop/airline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Unnamed: 0'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary with full airlines names\n",
    "airlines_names = pd.read_csv('/Users/marinejacquemin/Desktop/airlines.csv',sep=\";\")\n",
    "abbr_companies = airlines_names.set_index('IATA_CODE')['AIRLINE'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'AIRLINE_ID', 'CARRIER',\n",
       "       'ORIGIN_AIRPORT_ID', 'ORIGIN', 'ORIGIN_CITY_NAME', 'ORIGIN_STATE_ABR',\n",
       "       'ORIGIN_STATE_NM', 'DEST_AIRPORT_ID', 'DEST', 'DEST_CITY_NAME',\n",
       "       'DEST_STATE_ABR', 'DEST_STATE_NM', 'DEP_DELAY', 'DEP_TIME_BLK',\n",
       "       'ARR_DELAY', 'ARR_TIME_BLK', 'AIR_TIME', 'DISTANCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extreme values before fitting\n",
    "#data = data[data.DEP_DELAY < 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5556190, 21)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let's define X as the matrix contraining the quantitative features we need for further analysis.\n",
    "Y is the target vector, corresponding here to the Arrival Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X contains the quantitative features\n",
    "\n",
    "list_cat_var = ['AIRLINE_ID', 'CARRIER', 'ORIGIN_AIRPORT_ID', 'ORIGIN',\n",
    "       'ORIGIN_CITY_NAME', 'ORIGIN_STATE_ABR', 'ORIGIN_STATE_NM',\n",
    "       'DEST_AIRPORT_ID', 'DEST', 'DEST_CITY_NAME', 'DEST_STATE_ABR',\n",
    "       'DEST_STATE_NM']\n",
    "\n",
    "X = data.drop([x for x in list_cat_var],1)\n",
    "X = X.drop(['ARR_DELAY','DEP_DELAY'],1)\n",
    "X = X.fillna(0)\n",
    "\n",
    "#Y is the target (arrival delay)\n",
    "Y = data.ARR_DELAY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DEP_TIME_BLK', 'ARR_TIME_BLK',\n",
       "       'AIR_TIME', 'DISTANCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the features\n",
    "std_scale = StandardScaler().fit(X)\n",
    "X_scaled = std_scale.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's split the data into training and testing sets. \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X_scaled, Y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-241908ec9c94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# We train the model on the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# We train the model on the training set\n",
    "lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's compute the model performace\n",
    "\n",
    "# On récupère l'erreur de norme 2 sur le jeu de données test comme baseline\n",
    "baseline_error = np.mean((lr.predict(xtest) - ytest) ** 2)\n",
    "\n",
    "print(baseline_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On  crée le modèle de régression linéaire et on calcule les performances de cette régression\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(xtrain,ytrain)\n",
    "predictions = lm.predict(xtrain)\n",
    "print(\"MSE =\", metrics.mean_squared_error(predictions, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of predictions where the differences with real values is greater than 15 minutes\n",
    "icount = 0\n",
    "for i, val in enumerate(ytrain):\n",
    "    if abs(val-predictions[i]) > 15: icount += 1\n",
    "'{:.2f}%'.format(icount / len(predictions) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit(xtest,ytest)\n",
    "predictions = lm.predict(xtest)\n",
    "print(\"MSE =\", metrics.mean_squared_error(predictions, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Ecart = {:.2f} min'.format(np.sqrt(metrics.mean_squared_error(predictions, ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression polynomiale - ordre 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test avec ordre 2\n",
    "poly = PolynomialFeatures(degree = 2)\n",
    "regr = linear_model.LinearRegression()\n",
    "X_ = poly.fit_transform(xtrain)\n",
    "regr.fit(X_, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = regr.predict(X_)\n",
    "print(\"MSE =\", metrics.mean_squared_error(result, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcule du pourcentage d'écart >15min\n",
    "icount = 0\n",
    "for i, val in enumerate(ytrain):\n",
    "    if abs(val-result[i]) > 15: icount += 1\n",
    "'{:.2f}%'.format(icount / len(result) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = poly.fit_transform(xtest)\n",
    "result = regr.predict(X_)\n",
    "score = metrics.mean_squared_error(result, ytest)\n",
    "print(\"Mean squared error = \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Ecart = {:.2f} min'.format(np.sqrt(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit on the training set\n",
    "\n",
    "ridgereg = Ridge(alpha=0.3,normalize=True)\n",
    "poly = PolynomialFeatures(degree = 2)\n",
    "X_ = poly.fit_transform(xtrain)\n",
    "ridgereg.fit(X_, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing on the test set\n",
    "\n",
    "X_ = poly.fit_transform(xtest)\n",
    "result = ridgereg.predict(X_)\n",
    "score = metrics.mean_squared_error(result, ytest)\n",
    "print(\"Mean squared error = \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to determine the best model, we have two free parameters to adjust: the polynomial order and the  α  coefficient of the 'Ridge Regression' \n",
    "\n",
    "score_min = 10000\n",
    "for pol_order in range(2, 3):\n",
    "    for alpha in range(0, 10, 2):\n",
    "        ridgereg = Ridge(alpha = alpha/10, normalize=True)\n",
    "        poly = PolynomialFeatures(degree = pol_order)\n",
    "        regr = linear_model.LinearRegression()\n",
    "        X_ = poly.fit_transform(xtrain)\n",
    "        ridgereg.fit(X_, ytrain)        \n",
    "        X_ = poly.fit_transform(xtest)\n",
    "        result = ridgereg.predict(X_)\n",
    "        score = metrics.mean_squared_error(result, ytest)        \n",
    "        if score < score_min:\n",
    "            score_min = score\n",
    "            parameters = [alpha/10, pol_order]\n",
    "        print(\"n={} alpha={} , MSE = {:<0.5}\".format(pol_order, alpha, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on calcule la MSE avec les paramètres à l'optimum : \n",
    "\n",
    "ridgereg = Ridge(alpha = parameters[0], normalize=True)\n",
    "poly = PolynomialFeatures(degree = parameters[1])\n",
    "X_ = poly.fit_transform(X)\n",
    "ridgereg.fit(X_, Y)\n",
    "result = ridgereg.predict(X_)\n",
    "score = metrics.mean_squared_error(result, Y)        \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average error delay of : \n",
    "'Ecart = {:.2f} min'.format(np.sqrt(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score_ridge = r2_score(Y, result)\n",
    "print(\"r^2 on test data : %f\" % r2_score_ridge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the default CV\n",
    "alphas = [0.1, 1, 10, 100, 1e3, 1e4, 2e4, 5e4, 8e4, 1e5, 1e6, 1e7, 1e8]\n",
    "reg = linear_model.RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "#reg.fit(train_x, train_y, sample_weight=sample_weight)\n",
    "reg.fit(xtrain, ytrain)\n",
    "cv_mse = np.mean(reg.cv_values_, axis=0)\n",
    "print(\"alphas: %s\" % alphas)\n",
    "print(\"CV MSE: %s\" % cv_mse)\n",
    "print(\"Best alpha using built-in RidgeCV: %f\" % reg.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sous-forme graphique\n",
    "plt.plot(alphas,cv_mse)\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE vs. Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regLasso1 = Lasso(fit_intercept=False,normalize=False)\n",
    "print(regLasso1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "regLasso1.fit(xtrain,ytrain)\n",
    "#compute coefficients\n",
    "print(regLasso1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for optimal model\n",
    "#lasso path (10 valeurs de alpha à tester)\n",
    "\n",
    "my_alphas = numpy.array([0,0.001,0.01,0.05,0.1,0.2,0.3,0.4,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import lasso_path\n",
    "alpha_for_path, coefs_lasso, _ = lasso_path(xtrain,ytrain,alphas=my_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "couleurs = cm.rainbow(numpy.linspace(0,1,16))\n",
    "#graphique lasso path (une courbe par variable)\n",
    "for i in range(coefs_lasso.shape[0]):\n",
    "    plt.plot(alpha_for_path,coefs_lasso[i,:],c=couleurs[i])\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso path')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombre de coefs. non-nuls pour chaque alpha\n",
    "nbNonZero = numpy.apply_along_axis(func1d=numpy.count_nonzero,arr=coefs_lasso,axis=0)\n",
    "print(pd.DataFrame({'alpha':alpha_for_path,'Nb non-zero coefs':nbNonZero}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ou sous forme graphique\n",
    "plt.plot(alpha_for_path,nbNonZero) \n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Nb. de variables')\n",
    "plt.title('Nb. variables vs. Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for optimal solution\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "lcv = LassoCV(alphas=my_alphas,normalize=False,fit_intercept=False,random_state=0,cv=5)\n",
    "#lancement sur l'échantillon d'apprentissage\n",
    "lcv.fit(xtrain,ytrain)\n",
    "\n",
    "#valeurs des alphas qui ont été testés\n",
    "print(lcv.alphas_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moyenne mse en validation croisée pour chaque alpha\n",
    "avg_mse = numpy.mean(lcv.mse_path_,axis=1)\n",
    "#alphas vs. MSE en cross-validation\n",
    "print(pd.DataFrame({'alpha':lcv.alphas_,'MSE':avg_mse}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sous-forme graphique\n",
    "plt.plot(lcv.alphas_,avg_mse)\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE vs. Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best alpha\n",
    "print(lcv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction with this model\n",
    "ypLasso = lcv.predict(xtest)\n",
    "scorelasso = mean_squared_error(ytest,ypLasso)\n",
    "print(scorelasso)\n",
    "\n",
    "#résultats moins bon que les précédentes méthodes étudiées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average error delay of : \n",
    "'Ecart = {:.2f} min'.format(np.sqrt(scorelasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score_lasso = r2_score(ytest, ypLasso)\n",
    "print(\"r^2 on test data : %f\" % r2_score_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet = ElasticNet(alpha=alpha, l1_ratio=0.7)\n",
    "\n",
    "y_pred_enet = enet.fit(xtrain, ytrain).predict(xtest)\n",
    "r2_score_enet = r2_score(ytest, y_pred_enet)\n",
    "print(enet)\n",
    "print(\"r^2 on test data : %f\" % r2_score_enet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for optimal model\n",
    "\n",
    "from sklearn.linear_model import enet_path\n",
    "\n",
    "my_alphas_e = numpy.array([0.001,0.01,0.05,0.1,0.2,0.3,0.4,0.5,1,2,3])\n",
    "alpha_for_path, coefs_enet, _ = enet_path(xtrain,ytrain,alphas=my_alphas_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "couleurs = cm.rainbow(numpy.linspace(0,1,16))\n",
    "#graphique elastic net path (une courbe par variable)\n",
    "for i in range(coefs_enet.shape[0]):\n",
    "    plt.plot(alpha_for_path,coefs_enet[i,:],c=couleurs[i])\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Enet path')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombre de coefs. non-nuls pour chaque alpha\n",
    "nbNonZero = numpy.apply_along_axis(func1d=numpy.count_nonzero,arr=coefs_enet,axis=0)\n",
    "print(pd.DataFrame({'alpha':alpha_for_path,'Nb non-zero coefs':nbNonZero}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ou sous forme graphique\n",
    "plt.plot(alpha_for_path,nbNonZero) \n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Nb. de variables')\n",
    "plt.title('Nb. variables vs. Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recherche de la solution la plus performante\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "ecv = ElasticNetCV(alphas=my_alphas_e,normalize=False,fit_intercept=False,random_state=0,cv=5)\n",
    "#lancement sur l'échantillon d'apprentissage\n",
    "ecv.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moyenne mse en validation croisée pour chaque alpha\n",
    "avg_mse = numpy.mean(ecv.mse_path_,axis=1)\n",
    "#alphas vs. MSE en cross-validation\n",
    "print(pd.DataFrame({'alpha':ecv.alphas_,'MSE':avg_mse}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction avec ce modèle\n",
    "ypEnet = ecv.predict(xtest)\n",
    "\n",
    "print(mean_squared_error(ytest,ypEnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_enet = ecv.fit(xtrain, ytrain).predict(xtest)\n",
    "r2_score_enet = r2_score(ytest, y_pred_enet)\n",
    "print(\"r^2 on test data : %f\" % r2_score_enet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X contient les features quantitatives dont on a besoin\n",
    "\n",
    "list_cat_var = ['AIRLINE_ID','ORIGIN','DEST','CARRIER',\n",
    "       'ORIGIN_CITY_NAME', 'ORIGIN_STATE_ABR', 'ORIGIN_STATE_NM', 'DEST_CITY_NAME', 'DEST_STATE_ABR',\n",
    "       'DEST_STATE_NM']\n",
    "\n",
    "#data = data.fillna(0)\n",
    "data[\"MONTH\"] = data[\"MONTH\"].astype('category')\n",
    "data[\"DAY_OF_WEEK\"] = data[\"DAY_OF_WEEK\"].astype('category')\n",
    "data[\"DAY_OF_MONTH\"] = data[\"DAY_OF_MONTH\"].astype('category')\n",
    "data[\"ORIGIN_AIRPORT_ID\"] = data[\"ORIGIN_AIRPORT_ID\"].astype('category')\n",
    "data[\"DEST_AIRPORT_ID\"] = data[\"DEST_AIRPORT_ID\"].astype('category')\n",
    "\n",
    "#on filtre sur une compagnie, pour réduire le temps d'éxcution\n",
    "Xrf = data.loc[data['CARRIER'] == \"AA\"].drop([x for x in list_cat_var],1)\n",
    "Xrf = Xrf.drop(['ARR_DELAY','DEP_DELAY'],1)\n",
    "\n",
    "#Y est la target (le retard à l'arrivée)\n",
    "Yrf = data.loc[data['CARRIER'] == \"AA\"].ARR_DELAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on standardise les features\n",
    "std_scale = StandardScaler().fit(Xrf)\n",
    "X_scaled = std_scale.transform(Xrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on sépare le jeu de données entre training et testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xrf, Yrf, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des paramètres\n",
    "forest = RandomForestRegressor(n_estimators=20, max_depth=10,\n",
    "min_samples_split=2, min_samples_leaf=1,\n",
    "   max_features='auto', max_leaf_nodes=None,\n",
    "   bootstrap=True, oob_score=True)\n",
    "\n",
    "# apprentissage\n",
    "forest = forest.fit(x_train,y_train)\n",
    "print(1-forest.oob_score_)\n",
    "\n",
    "# erreur de prévision sur le test\n",
    "1-forest.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimisation du paramètre max_features par validation croisée.\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param=[{\"max_features\":list(range(2,8))}]\n",
    "delay_rf= GridSearchCV(RandomForestRegressor(\n",
    "n_estimators=15,max_depth=10),param,cv=5,n_jobs=-1)\n",
    "delay_rf=delay_rf.fit(x_train, y_train)\n",
    "\n",
    "# paramètre optimal\n",
    "param = delay_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilisation de la valeur optimale\n",
    "￼forest = RandomForestRegressor(n_estimators=20, max_depth=10,\n",
    "   min_samples_split=2, min_samples_leaf=1,max_features=param)\n",
    "\n",
    "# apprentissage\n",
    "forest = forest.fit(x_train,y_train)\n",
    "\n",
    "predictions = forest.predict(x_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2),\"min\")\n",
    "\n",
    "score_rf = mean_squared_error(y_test,predictions)\n",
    "print(score_rf)\n",
    "\n",
    "r2_score_rf = r2_score(y_test, predictions)\n",
    "print(\"r^2 on test data : %f\" % r2_score_rf)\n",
    "\n",
    "#average error delay of : \n",
    "'Ecart = {:.2f} min'.format(np.sqrt(score_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
